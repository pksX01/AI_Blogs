{
  
    
        "post0": {
            "title": "Bear Classification",
            "content": "Install and import the necessary fast.ai packages. . !pip install -Uqq fastbook . import fastai from fastbook import * . from fastai.vision.widgets import * . Downloading sample image of grazzly bears for demonstration. &lt;/br&gt; We will be using Duckduckgo for downloading the images which is free to use. Even no account is needed to use it. . urls = search_images_ddg(&#39;grizzly&#39;, max_images = 100) urls[0] #Sample image . len(urls) #No of urls returned . dest = &#39;./input/grizzly.jpg&#39; download_url(urls[0], dest) . Let&#39;s display the downloaded image . sample_img = PILImage.create(dest) sample_img.to_thumb(128, 128) . Download the images of all types of bears required for our model . We will download hundreds of images for each type of bear using Duckduckgo search engine as we did above for just one image of grizzly bear. . bear_types = (&#39;grizzly&#39;, &#39;black&#39;, &#39;teddy&#39;) #Creating a tuple of types of bears path = Path(&#39;bears&#39;) path . type(bear_types) . for bear_type in bear_types: print(bear_type) . Downloading images for each type of bear in a separate sub-directories in &#39;bears&#39; directory . if not path.exists(): path.mkdir() #Creating parent directory &#39;bears&#39; for bear_type in bear_types: dest = (path/bear_type) dest.mkdir() #Creating directory for each type of bear results = search_images_ddg(f&#39;{bear_type} bear&#39;, max_images = 100) download_images(dest, urls=results) . Since images should be downloaded in their respective folders, let&#39;s verify the folders and images if they are downladed. . path.ls() #Shows the folders available at that path . get_image_files gets the list of the path of all images in a Path object . fns = get_image_files(path) fns . Sometimes the images downloaded from internet are corrupt. So, let&#39;s check if that is the case. . failed = verify_images(fns) failed . As we can see above, there are 3 failed/corrupt images hence unlinking them from our dataset. . failed.map(Path.unlink); . DataLoaders . We will be using DataBlock API to create DataLoaders as it provides the custom functionalities. Dataloaders loads the data in the required format for the model.&lt;/br&gt; We need to provide the data type information for independent variable and dependent using blocks. ImageBlock represents that our independent variables are images and CategoryBlock represents that model needs to classify the images into different categories.&lt;/br&gt; We have to tell how to get a list of input files. For this, we have to pass a function to the get_items parameter. As mentioned above, get_image_files returns the list of path of all images.&lt;/br&gt; RandomSplitter splits the dataset randomly in two sets: Training sets and Validation sets. valid_pct=0.2 tells splitter to use 20% of total data as validation set. seed=20 makes sure that we are getting same set of images in validation set in different epochs so that model can&#39;t see these images part of validation set during training. &lt;/br&gt; get_y = parent_label tells the Dataloader to get the name of parent folder as label for all images.&lt;/br&gt; item_tfms is used to perform the transformations on individual images. Resize(128) will resize the images into 128x128 pixels. . bears_data_block = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, splitter = RandomSplitter(valid_pct=0.2, seed=20), get_y = parent_label, item_tfms = Resize(128) ) . Loading the data using datalaoder. . dls = bears_data_block.dataloaders(path) . DataLoaders includes Training and Validation Dataloaders. Dataloaders provide the batches of few items at a time to the GPU.&lt;/br&gt; Let&#39;s see some of the images from Training and Testing Dataloaders. . We need to tell how many images we want to get displayed in how many rows. Default value of max_n is 9. . dls.train.show_batch(max_n=4, nrows=1) . dls.valid.show_batch(max_n=4, nrows=1) . By default, Resize crops the images in the squared shape of requested size using the full height or weight of the image. We shlould always keep in mind that cropping the image will cause the loss of some information. Let&#39;s try some more types of Resizing method to understand this.&lt;/br&gt; To apply transformations on existing DataBlock, datablock&#39;s new() method is used.&lt;/br&gt; Here, we will squish the images in the 128x128 pixels image. . bears_data_block = bears_data_block.new(item_tfms = Resize(128, ResizeMethod.Squish)) dls = bears_data_block.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . Here, we will pad the images with zeros (black). . bears_data_block = bears_data_block.new(item_tfms = Resize(128, ResizeMethod.Pad, pad_mode=&#39;zeros&#39;)) dls = bears_data_block.dataloaders(path) dls.show_batch(max_n = 4, nrows = 1) . As we can see in above images, if we squish or pad the images or resize them in the square shape, it will always lose some information. . Now we are going to randomly crop the images which is very common resizing method. In this method, different parts of images will be cropped in different epoch so that model could learn every important feature. min_scale determines how much of the image to be cropped each time. . bears_data_block = bears_data_block.new(item_tfms = RandomResizedCrop(128, min_scale=0.3)) dls = bears_data_block.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . To have same image repeated for each version of RandomResizedCrop transform, we need to use unique=True. . dls.valid.show_batch(max_n=4, nrows=1, unique=True) . Data Augmentation . Data augmentation means creating different versions of input data such that they appear different but carry same meaning. Some of the common data augmentation techniques are rotation, flipping, warping, brightness changes and contrats changes etc.&lt;/br&gt; aug_transforms includes standard set of augmentation techniques. To apply these transformations on batch of data using GPU, we can set this in batch_tfms parameter in DataBlock.&lt;/br&gt; The value of mult decides the extent to which data augmentation is performed. . bears_data_block = bears_data_block.new(item_tfms = Resize(128), batch_tfms = aug_transforms(mult=2)) dls = bears_data_block.dataloaders(path) dls.train.show_batch(max_n=4, nrows=1, unique=True) . All four images are actually same image after augmentation. We can see the Rotation in first and third images, increased brightness in 4th image. . bears_data_block = bears_data_block.new(item_tfms = Resize(128), batch_tfms = aug_transforms(mult=3)) dls = bears_data_block.dataloaders(path) dls.train.show_batch(max_n=4, nrows=1, unique=True) . In the above images, we can clearly see the effect of change in value of mult. . Training the Model . Now we will train our model. Here, I am creating a new DataBlock with RandomResizedCrop for individual item transformations and aug_transforms for batch transformations. . bears_data_block = DataBlock( blocks = (ImageBlock, CategoryBlock), get_items = get_image_files, splitter = RandomSplitter(valid_pct=0.2, seed=4), get_y = parent_label, item_tfms = RandomResizedCrop(224, min_scale = 0.3), batch_tfms = aug_transforms(mult=1) ) . dls = bears_data_block.dataloaders(path) . learn = cnn_learner(dls, resnet18, metrics=error_rate) . learn.fine_tune(4) . We have achieved 100% accuracy in just 4 epochs during training. . Confusion Matrix . Confusion matrix is used to see how many inputs are wrongly labeled. Diagonal of the matrix shows the images that are classified correctly. Other cells represent the wrongly classified images. In this case, all images are classified correctly. &lt;/br&gt; Note: Confusion matrix is calculated using validation set. . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . plot_top_losses shows us the images with highest loss. It also includes the correctly classified images with low confidence. Images will be labeled with four things: Prediction, actual value, loss, and probability. . interp.plot_top_losses(5, nrows=1) . Cleaning Data after Training . Generally, we do data cleaning before the training of the model but fast.ai provides us a way to do data cleaning even after the training of the model. It lets us see the data in training and validation sets and we can decide whether we want to delete or re-label them. . ImageClassifierCleaner do not delete the images. It allows us to select images where images are displayed in the decreasing loss order (highest loss to lowest). It provides a GUI having menues with the option to keep, delete or re-label. . cleaner = ImageClassifierCleaner(learn) cleaner . To delete the images, we need to select delete option for that respective image. ImageClassifierCleaner will not delete the images, instead it provides us the indices of those images. We can use those indices to unlink them. . for i in cleaner.delete(): cleaner.fns[i].unlink() . To move images for which we have selected category, we need to run following code. . for i, category in cleaner.change(): shutil.move(str(cleaner.fns[i]), path/category) . After the incorrect labelled are either deleted or re-labeled after the training, we can re-train the model. But since our model alreay achieved 100% accuracy on validation set, we are not going to re-train the model. . Using the model for Inference . Now since our model are trained, it&#39;s inference time. Since the model is trained in this notebook itself, we can directly do the ineference. But I am going to show a way we can do the inference in case of training would have happened in some other notebook.&lt;/br&gt; First, we need to export the model. We will use the export() method. It will export the model in .pkl format which we can use further for inference anywhere either in this notebook or another notebook or any kind of app. . learn.export() . Let&#39;s confirm if there is any .pkl file since we have exported the model. . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . We can see there is a .pkl file which is our exported model. . Before doing the inference/prediction, we need to load the exported the model. . predictor = load_learner(path/&#39;export.pkl&#39;) . Since our model is loaded back, we can do the prediction/inference. . predictor.predict(&#39;../input/sample-cat-image/bear_img.jpeg&#39;) . There are 3 things that predict() method gives us.&lt;/br&gt; (1) Predicted Value&lt;/br&gt; (2) Index of the predicted category&lt;/br&gt; (3) List of probabilities&lt;/br&gt; . Second value tells which value to look in the list of probabilities. Here value at index 1 is the probability of given bear being a grizzly bear i.e. 0.999998. . This index will be the same as index of predicted category in vocab of dataloader. . predictor.dls.vocab . Creating GUI for the notebook app . In this section, we are going to create a GUI inside the notebook itself. It will be like a mini web app for our model inference. We will use iPython widgets for this purpose. fast.ai provides us these widgets as well. . from fastai.vision.widgets import * . First, we will create the upload button which will let us uplaod the image needed for prediction. . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . Creating an output button to display the image. . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . Getting the prediction of the uploaded image. . pred, pred_idx, prob = predictor.predict(img) . Creating a Label widgets which will show the prediction in the form of a sentence. . label = widgets.Label() label.value = f&#39;Prediction: {pred}, Probability: {prob[pred_idx]:.04f}&#39; label . Now, we will create a button to classify the images but this button will not do anything unless we define the on-click behaviour for this button. . predict_btn = widgets.Button(description=&#39;Classify&#39;) predict_btn . Since we have shown all the components separately, it&#39;s time to pull up all of them together and put them in a vertical box to look like a mini web app. For this, we are going to define all those widgets again. . upload_btn = widgets.FileUpload() output = widgets.Output() label_btn = widgets.Label() predict_btn = widgets.Button(description=&#39;Classify&#39;) . Defining the on-click behaviour of the classify button : . def on_click_classify(change): img = PILImage.create(upload_btn.data[-1]) output.clear_output() with output: display(img.to_thumb(128,128)) pred, pred_idx, prob = predictor.predict(img) label_btn.value = f&#39;Prediction: {pred}, Probability: {prob[pred_idx]:.04f}&#39; . predict_btn.on_click(on_click_classify) . Finally, create a virtual box vbox widget to accomodate all other widgets inside it. Hurray, our app is ready now to do the prediction. . VBox([widgets.Label(&#39;Upload the picture of a bear&#39;), upload_btn, predict_btn, output, label_btn]) .",
            "url": "https://pksx01.github.io/pks.ai/2022/03/26/fast-ai-course-1-lesson-2-bear-classification.html",
            "relUrl": "/2022/03/26/fast-ai-course-1-lesson-2-bear-classification.html",
            "date": " • Mar 26, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://pksx01.github.io/pks.ai/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://pksx01.github.io/pks.ai/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://pksx01.github.io/pks.ai/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pksx01.github.io/pks.ai/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}